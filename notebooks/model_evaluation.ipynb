{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis of Final Selected Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents <a name=\"toc\"></a>\n",
    "- [Import packages](#1)\n",
    "- [Large loans model candidates](#2)\n",
    "- [Small loans model candidates](#3)\n",
    "- [Large loans threshold selection](#4)\n",
    "- [Small loans threshold selection](#5)\n",
    "- [Final model selection](#6)\n",
    "- [Error analysis](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages <a name=\"1\"></a>\n",
    "\n",
    "* Includes models, config, and helpers\n",
    "* Packages for visualisation and plotting\n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src import config\n",
    "from src.evaluation import evaluate_report\n",
    "from src.model_dispatcher import (large_models, \n",
    "                                  small_models, \n",
    "                                  large_models_threshold_sel, \n",
    "                                  small_models_threshold_sel)\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "mpl.rcParams['figure.figsize'] = config.DEFAULT_FIGSIZE\n",
    "mpl.rcParams['lines.linewidth'] = config.DEFAULT_PLOT_LINEWIDTH\n",
    "mpl.rcParams['lines.linestyle'] = config.DEFAULT_PLOT_LINESTYLE\n",
    "mpl.rcParams['font.size'] = config.DEFAULT_AXIS_FONT_SIZE\n",
    "\n",
    "pal = sns.color_palette(\"deep\")\n",
    "pal_hex = pal.as_hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large loans model candidates <a name=\"2\"></a>\n",
    "\n",
    "* Process to select the optimal model specification includes:\n",
    "* Reading in the test data and model candidates\n",
    "* Generate ROC curves and classification reports for each large loans candidate\n",
    "* The final selection is GBM for large loans\n",
    "\n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_300000.parquet\")\n",
    "\n",
    "X_large_test = ll_test.drop(columns=config.TARGET)\n",
    "y_large_test = ll_test[config.TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the ROC curves for candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "plt.plot([0, 1], [0, 1], ls=\"--\", color=\"black\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"Large loans - ROC Curves\")\n",
    "run = 0\n",
    "\n",
    "for name, model in large_models.items():\n",
    "    y_pred_prob = model.predict_proba(X_large_test)[:,1]\n",
    "    y_pred = model.predict(X_large_test)\n",
    "    fpr, tpr, _ = roc_curve(y_large_test, y_pred_prob)\n",
    "    auc = roc_auc_score(y_large_test, y_pred_prob)\n",
    "\n",
    "    ax.plot(\n",
    "        fpr, tpr, \n",
    "        label=f\"{name}: AUC {auc:.2%}\", \n",
    "        linestyle=\"solid\", \n",
    "        linewidth=2,\n",
    "        color=pal_hex[run]\n",
    "    )\n",
    "    run += 1\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(config.REPORTS_PATH / \"roc/all_large_models_300000.jpeg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_results = []\n",
    "\n",
    "for name, model in large_models.items():\n",
    "    y_pred_prob = model.predict_proba(X_large_test)[:,1]\n",
    "    y_pred = model.predict(X_large_test)\n",
    "    report = evaluate_report(y_test=y_large_test, y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    report[\"model\"] = name\n",
    "    ll_results.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the results to a DataFrame and export if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "large_model_metrics = pd.DataFrame(ll_results).set_index(\"model\")\n",
    "large_model_metrics\n",
    "\n",
    "# export results to csv if needed\n",
    "# large_model_metrics.to_csv(\"large_model_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small loans model candidates <a name=\"3\"></a>\n",
    "\n",
    "* Process to select the optimal model specification includes:\n",
    "* Reading in the test data and model candidates\n",
    "* Generate ROC curves and classification reports for each small loans candidate\n",
    "* The final selection is RF for small loans\n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_300000.parquet\")\n",
    "\n",
    "X_small_test = sl_test.drop(columns=config.TARGET)\n",
    "y_small_test = sl_test[config.TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the ROC curves for candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "plt.plot([0, 1], [0, 1], ls=\"--\", color=\"black\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"Small loans - ROC Curves\")\n",
    "run = 0\n",
    "\n",
    "for name, model in small_models.items():\n",
    "    y_pred_prob = model.predict_proba(X_small_test)[:,1]\n",
    "    y_pred = model.predict(X_small_test)\n",
    "    fpr, tpr, _ = roc_curve(y_small_test, y_pred_prob)\n",
    "    auc = roc_auc_score(y_small_test, y_pred_prob)\n",
    "\n",
    "    ax.plot(\n",
    "        fpr, tpr, \n",
    "        label=f\"{name}: AUC {auc:.2%}\", \n",
    "        linestyle=\"solid\", \n",
    "        linewidth=2,\n",
    "        color=pal_hex[run]\n",
    "    )\n",
    "    run += 1\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(config.REPORTS_PATH / \"roc/all_small_models_300000.jpeg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_results = []\n",
    "\n",
    "for name, model in small_models.items():\n",
    "    y_pred_prob = model.predict_proba(X_small_test)[:,1]\n",
    "    y_pred = model.predict(X_small_test)\n",
    "    report = evaluate_report(y_test=y_small_test, y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    report[\"model\"] = name\n",
    "    sl_results.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the results to a DataFrame and export if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "small_model_metrics = pd.DataFrame(sl_results).set_index(\"model\")\n",
    "small_model_metrics\n",
    "\n",
    "# export results to csv if needed\n",
    "# small_model_metrics.to_csv(\"small_model_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large loans threshold selection <a name=\"4\"></a>\n",
    "\n",
    "* Selection process: Reading in the necessary data files and models \n",
    "* ROC curves and classification reports are then generated for each large loan threshold candidate\n",
    "* We select the best performing large loans model with consideration to the small loan's performance\n",
    "* The final threshold selected is 400k \n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_200000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_200000.parquet\")\n",
    "ll_300000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_300000.parquet\")\n",
    "ll_400000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_400000.parquet\")\n",
    "ll_500000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_500000.parquet\")\n",
    "\n",
    "X_large_200000_test = ll_200000_test.drop(columns=config.TARGET)\n",
    "y_large_200000_test = ll_200000_test[config.TARGET]\n",
    "X_large_300000_test = ll_300000_test.drop(columns=config.TARGET)\n",
    "y_large_300000_test = ll_300000_test[config.TARGET]\n",
    "X_large_400000_test = ll_400000_test.drop(columns=config.TARGET)\n",
    "y_large_400000_test = ll_400000_test[config.TARGET]\n",
    "X_large_500000_test = ll_500000_test.drop(columns=config.TARGET)\n",
    "y_large_500000_test = ll_500000_test[config.TARGET]\n",
    "\n",
    "ll_evaluation = {\n",
    "    \"gbm_200000\": [X_large_200000_test, y_large_200000_test],\n",
    "    \"gbm_300000\": [X_large_300000_test, y_large_300000_test],\n",
    "    \"gbm_400000\": [X_large_400000_test, y_large_400000_test],\n",
    "    \"gbm_500000\": [X_large_500000_test, y_large_500000_test]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the ROC curves for candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "plt.plot([0, 1], [0, 1], ls=\"--\", color=\"black\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"Large loans - GBM threshold selection - ROC Curves\")\n",
    "run = 0\n",
    "\n",
    "for name, data in ll_evaluation.items():\n",
    "    model = large_models_threshold_sel.get(name)\n",
    "    y_pred_prob = model.predict_proba(data[0])[:,1]\n",
    "    y_pred = model.predict(data[0])\n",
    "    fpr, tpr, _ = roc_curve(data[1], y_pred_prob)\n",
    "    auc = roc_auc_score(data[1], y_pred_prob)\n",
    "\n",
    "    ax.plot(\n",
    "        fpr, tpr, \n",
    "        label=f\"{name}: AUC {auc:.2%}\", \n",
    "        linestyle=\"solid\", \n",
    "        linewidth=2,\n",
    "        color=pal_hex[run]\n",
    "    )\n",
    "    run += 1\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(config.REPORTS_PATH / \"roc/large_models_threshold_sel.jpeg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate report\n",
    "\n",
    "ll_threshold_candidates_results = []\n",
    "\n",
    "for name, data in ll_evaluation.items():\n",
    "    model = large_models_threshold_sel.get(name)\n",
    "    y_pred_prob = model.predict_proba(data[0])[:,1]\n",
    "    y_pred = model.predict(data[0])\n",
    "    report = evaluate_report(y_test=data[1], y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    report[\"model\"] = name\n",
    "    ll_threshold_candidates_results.append(report)\n",
    "\n",
    "ll_threshold_candidates_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the results to a DataFrame and export if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "large_model_thresholds = pd.DataFrame(ll_threshold_candidates_results).set_index(\"model\")\n",
    "large_model_thresholds\n",
    "\n",
    "# export results to csv if needed\n",
    "# large_model_thresholds.to_csv(\"large_model_threshold_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small loans threshold selection <a name=\"5\"></a>\n",
    "\n",
    "* Selection process: Reading in the necessary data files and models \n",
    "* ROC curves and classification reports are then generated for each small loan threshold candidate\n",
    "* We select the best performing small loans model with consideration to the large loan's performance\n",
    "* The final threshold selected is 400k\n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_200000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_200000.parquet\")\n",
    "sl_300000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_300000.parquet\")\n",
    "sl_400000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_400000.parquet\")\n",
    "sl_500000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_500000.parquet\")\n",
    "\n",
    "X_small_200000_test = sl_200000_test.drop(columns=config.TARGET)\n",
    "y_small_200000_test = sl_200000_test[config.TARGET]\n",
    "X_small_300000_test = sl_300000_test.drop(columns=config.TARGET)\n",
    "y_small_300000_test = sl_300000_test[config.TARGET]\n",
    "X_small_400000_test = sl_400000_test.drop(columns=config.TARGET)\n",
    "y_small_400000_test = sl_400000_test[config.TARGET]\n",
    "X_small_500000_test = sl_500000_test.drop(columns=config.TARGET)\n",
    "y_small_500000_test = sl_500000_test[config.TARGET]\n",
    "\n",
    "sl_evaluation = {\n",
    "    \"rf_200000\": [X_small_200000_test, y_small_200000_test],\n",
    "    \"rf_300000\": [X_small_300000_test, y_small_300000_test],\n",
    "    \"rf_400000\": [X_small_400000_test, y_small_400000_test],\n",
    "    \"rf_500000\": [X_small_500000_test, y_small_500000_test]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the ROC curves for candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "plt.plot([0, 1], [0, 1], ls=\"--\", color=\"black\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"Small loans - RF threshold selection - ROC Curves\")\n",
    "run = 0\n",
    "\n",
    "for name, data in sl_evaluation.items():\n",
    "    model = small_models_threshold_sel.get(name)\n",
    "    y_pred_prob = model.predict_proba(data[0])[:,1]\n",
    "    y_pred = model.predict(data[0])\n",
    "    fpr, tpr, _ = roc_curve(data[1], y_pred_prob)\n",
    "    auc = roc_auc_score(data[1], y_pred_prob)\n",
    "\n",
    "    ax.plot(\n",
    "        fpr, tpr, \n",
    "        label=f\"{name}: AUC {auc:.2%}\", \n",
    "        linestyle=\"solid\", \n",
    "        linewidth=2,\n",
    "        color=pal_hex[run]\n",
    "    )\n",
    "    run += 1\n",
    "\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig(config.REPORTS_PATH / \"roc/small_models_threshold_sel.jpeg\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the classification report for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate report\n",
    "\n",
    "sl_threshold_candidates_results = []\n",
    "\n",
    "for name, data in sl_evaluation.items():\n",
    "    model = small_models_threshold_sel.get(name)\n",
    "    y_pred_prob = model.predict_proba(data[0])[:,1]\n",
    "    y_pred = model.predict(data[0])\n",
    "    report = evaluate_report(y_test=data[1], y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    report[\"model\"] = name\n",
    "    sl_threshold_candidates_results.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the results to a DataFrame and export if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "small_model_thresholds = pd.DataFrame(sl_threshold_candidates_results).set_index(\"model\")\n",
    "small_model_thresholds\n",
    "\n",
    "# export results to csv if needed\n",
    "# small_model_thresholds.to_csv(\"small_model_threshold_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model selection <a name=\"6\"></a>\n",
    "\n",
    "* In order to select our final models, we will assume that our data is representative and calculate the expected model's discriminativeness \n",
    "* This is done by taking the weighted average of the AUC \n",
    "* The best combination results at the 300K threshold \n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_200000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_200000.parquet\")\n",
    "ll_300000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_300000.parquet\")\n",
    "ll_400000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_400000.parquet\")\n",
    "ll_500000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_500000.parquet\")\n",
    "sl_200000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_200000.parquet\")\n",
    "sl_300000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_300000.parquet\")\n",
    "sl_400000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_400000.parquet\")\n",
    "sl_500000_test = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_500000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation \n",
    "threshold_200000 = (84.10 * sl_200000_test.shape[0] / (sl_200000_test.shape[0] + ll_200000_test.shape[0])) + (88.50 * ll_200000_test.shape[0] / (sl_200000_test.shape[0] + ll_200000_test.shape[0]))\n",
    "threshold_300000 = (84.57 * sl_300000_test.shape[0] / (sl_300000_test.shape[0] + ll_300000_test.shape[0])) + (89.28 * ll_300000_test.shape[0] / (sl_300000_test.shape[0] + ll_300000_test.shape[0]))\n",
    "threshold_400000 = (85.19 * sl_400000_test.shape[0] / (sl_400000_test.shape[0] + ll_400000_test.shape[0])) + (89.83 * ll_400000_test.shape[0] / (sl_400000_test.shape[0] + ll_400000_test.shape[0]))\n",
    "threshold_500000 = (86.20 * sl_500000_test.shape[0] / (sl_500000_test.shape[0] + ll_500000_test.shape[0])) + (89.00 * ll_500000_test.shape[0] / (sl_500000_test.shape[0] + ll_500000_test.shape[0]))\n",
    "\n",
    "print(f\"\"\"\n",
    "200000 Threshold: {threshold_500000:.2f}%\n",
    "300000 Threshold: {threshold_300000:.2f}%\n",
    "400000 Threshold: {threshold_400000:.2f}%\n",
    "500000 Threshold: {threshold_500000:.2f}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis <a name=\"7\"></a>\n",
    "\n",
    "* Given our final models - what kinds of observations are our models misclassifying?\n",
    "* What are some potential reasons for the misclassification? \n",
    "* Approach to diagnose is to look at the FPs\n",
    "\n",
    "[back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large loans \n",
    "\n",
    "Steps\n",
    "* Load in the GBM model with threshold 300,000\n",
    "* Identify the misclassified observations\n",
    "* Generate proportions for misclassified observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_model = large_models_threshold_sel.get(\"gbm_300000\")\n",
    "\n",
    "ll_test_300000 = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_large_loans_300000.parquet\").reset_index(drop=True)\n",
    "X_ll_test_300000 = ll_test_300000.drop(columns=config.TARGET)\n",
    "y_ll_test_300000 = ll_test_300000[config.TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(ll_model.predict(X_ll_test_300000))\n",
    "ll_test_300000[\"prediction\"] = y_pred\n",
    "\n",
    "# tag misclassified observations\n",
    "ll_test_300000[\"false_positives\"] = np.where((ll_test_300000[\"status\"] == 0) & (ll_test_300000[\"prediction\"] == 1), 1, 0)\n",
    "ll_test_300000[\"false_negatives\"] = np.where((ll_test_300000[\"status\"] == 1) & (ll_test_300000[\"prediction\"] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any particular demographics? \n",
    "demographics_subset = [\"gender_j\", \"gender_m\", \"gender_na\", \n",
    "                       \"age_25-34\", \"age_35-44\", \"age_45-54\",\n",
    "                       \"age_55-64\", \"age_65-74\", \"age_>74\", \"region_north\",\n",
    "                       \"region_north-east\", \"region_south\"]\n",
    "misclassified_dem = ll_test_300000.loc[ll_test_300000[\"false_positives\"], demographics_subset]\n",
    "\n",
    "mean_misclassified_dem = misclassified_dem.describe().to_numpy()[1]\n",
    "mean_actuals_dem = ll_test_300000[demographics_subset].describe().to_numpy()[1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "sns.barplot(x=mean_misclassified_dem, y=demographics_subset, color=pal_hex[0])\n",
    "\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "plt.title(\"Misclassified results originate from specific genders, ages and regions\")\n",
    "plt.xlabel(\"Proportion of misclassified results\")\n",
    "\n",
    "plt.savefig(\"misclassified_dem\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diving deeper into the characteristics of the model, we notice that the misclassifications for \n",
    "false positives tend to: \n",
    "* Have a higher loan amount \n",
    "* Have lower loan limit and credit worthiness \n",
    "\n",
    "This implies that our model might be classifying these observations as potential defaulters based on a representation of risk - ie. individuals who borrow higher but might not have stellar credit worthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_na_groupby = ll_test_300000.groupby(\"gender_na\")[[\"loan_limit\", \"credit_worthiness\", \"loan_amount\"]].mean()\n",
    "region_south_groupby = ll_test_300000.groupby(\"region_south\")[[\"loan_limit\", \"credit_worthiness\", \"loan_amount\"]].mean()\n",
    "age_45_54_groupby = ll_test_300000.groupby(\"age_45-54\")[[\"loan_limit\", \"credit_worthiness\", \"loan_amount\"]].mean()\n",
    "\n",
    "display(region_south_groupby)\n",
    "display(gender_na_groupby)\n",
    "display(age_45_54_groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small loans \n",
    "\n",
    "We carry out a similar approach to the large loans \n",
    "* Load in the RF model with threshold 300,000\n",
    "* Identify the misclassified observations\n",
    "* Generate proportions for misclassified observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_model = small_models_threshold_sel.get(\"rf_300000\")\n",
    "\n",
    "sl_test_300000 = pd.read_parquet(config.FIN_FILE_PATH / \"test_df_small_loans_300000.parquet\").reset_index(drop=True)\n",
    "X_sl_test_300000 = sl_test_300000.drop(columns=config.TARGET)\n",
    "y_sl_test_300000 = sl_test_300000[config.TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(ll_model.predict(X_sl_test_300000))\n",
    "sl_test_300000[\"prediction\"] = y_pred\n",
    "\n",
    "# tag misclassified observations\n",
    "sl_test_300000[\"false_positives\"] = np.where((sl_test_300000[\"status\"] == 0) & (sl_test_300000[\"prediction\"] == 1), 1, 0)\n",
    "sl_test_300000[\"false_negatives\"] = np.where((sl_test_300000[\"status\"] == 1) & (sl_test_300000[\"prediction\"] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any particular demographics? \n",
    "demographics_subset = [\"gender_j\", \"gender_m\", \"gender_na\", \n",
    "                       \"age_25-34\", \"age_35-44\", \"age_45-54\",\n",
    "                       \"age_55-64\", \"age_65-74\", \"age_>74\", \"region_north\",\n",
    "                       \"region_north-east\", \"region_south\"]\n",
    "misclassified_dem = sl_test_300000.loc[sl_test_300000[\"false_positives\"], demographics_subset]\n",
    "\n",
    "mean_misclassified_dem = misclassified_dem.describe().to_numpy()[1]\n",
    "mean_actuals_dem = sl_test_300000[demographics_subset].describe().to_numpy()[1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.tight_layout()\n",
    "sns.barplot(x=mean_misclassified_dem, y=demographics_subset, color=pal_hex[0])\n",
    "\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "plt.title(\"The case is similar for small loans, but with a more pronounced focus on 55-64\")\n",
    "plt.xlabel(\"Proportion of misclassified results\")\n",
    "\n",
    "plt.savefig(\"misclassified_dem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a similar pattern in the small loans dataset - gender NA and region south tend to be misclassified - an appropriate follow up step would be to try and gather more data from these subsets so that the model has more examples to learn from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_55_64_groupby = sl_test_300000.groupby(\"age_55-64\")[[\"loan_limit\", \"credit_worthiness\", \"loan_amount\", \"lump_sum_payment\"]].mean()\n",
    "display(age_55_64_groupby)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "570095cd93adf9a4e6271b94630cfbadf31bbfe8ef42337a7894ca3063fc1c9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
