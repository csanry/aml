{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All missingness and their relationships run here\n",
    "\n",
    "Overall missingness \n",
    "\n",
    "Missingness relationships \n",
    "\n",
    "Hypotheses for missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Libraries and Imports](#1)\n",
    "2. [Statistics](#2)\n",
    "3. [aa](#3)\n",
    "4. [bb](#4)\n",
    "5. [cc](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base \n",
    "import os \n",
    "import sys\n",
    "from src import helpers, config, plotting, evaluation\n",
    "import random \n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pandas.api.types as types\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Set, Dict, Tuple\n",
    "from typing import Union, Any, Optional, Iterable, Hashable, Type\n",
    "\n",
    "# base\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# ml preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "# models\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# validation \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_validate, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, roc_curve, roc_auc_score, precision_score, recall_score, plot_confusion_matrix\n",
    "\n",
    "# pipelines \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# ignore warnings \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "# yet to arrange\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert config.FIN_FILE_PATH == Path.cwd().parent / \"data\" / \"final\"\n",
    "assert config.REPORTS_PATH == Path.cwd().parent / \"reports\" / \"figures\"\n",
    "assert config.RAW_FILE_PATH == Path.cwd().parent / \"data\" / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target column\n",
    "%matplotlib inline \n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_palette('deep')\n",
    "mpl.rcParams['figure.figsize'] = config.DEFAULT_FIGSIZE\n",
    "mpl.rcParams['lines.linewidth'] = config.DEFAULT_PLOT_LINEWIDTH\n",
    "mpl.rcParams['lines.linestyle'] = config.DEFAULT_PLOT_LINESTYLE\n",
    "mpl.rcParams['font.size'] = config.DEFAULT_AXIS_FONT_SIZE\n",
    "\n",
    "df = pd.read_parquet(config.INT_FILE_PATH / config.INT_FILE_NAME)\n",
    "\n",
    "train = pd.read_parquet(config.FIN_FILE_PATH / 'train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.missingness_checks(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.missingness_checks(df.sort_values(by='status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.quick_eda(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.quick_plot(df[['status', 'loan_amount', 'rate_of_interest', 'upfront_charges', 'term', \n",
    "                'property_value', 'income', 'credit_score', 'ltv', 'dtir1']].sample(10000), hue=config.TARGET)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypotheses \n",
    "\n",
    "1. To drop \n",
    "    - id -> UID\n",
    "    - year -> No variation \n",
    "    - interest_rate_spread -> Not able to discriminate\n",
    "\n",
    "1. Demographics\n",
    "    - Gender -> Joint less likely to default\n",
    "        - Engineer whether loan was joint or not\n",
    "        - Sex not provided\n",
    "\n",
    "2. Loan types \n",
    "    - loan_type -> what is a type 2 loan? \n",
    "    - loan_limit -> missing values -> ncf tends to default more \n",
    "    - lump_sum_payment -> \n",
    "    - approv_in_adv -> NA 908\n",
    "    - term -> most likely not going to be discriminating\n",
    "\n",
    "3. Purpose \n",
    "    - loan_purpose\n",
    "    - credit_worthiness\n",
    "    - open_credit -> imbalanced might not be worth to compute\n",
    "    - business_or_commercial -> higher chance of default if biz/comm\n",
    "    - \n",
    "\n",
    "4. Deterministic \n",
    "    - construction_type\n",
    "    \n",
    "\n",
    "loan_limit                    3344\n",
    "approv_in_adv                  908\n",
    "loan_purpose                   134\n",
    "rate_of_interest             36439\n",
    "upfront_charges              39642\n",
    "term                            41\n",
    "neg_ammortization              121\n",
    "interest_only                    0\n",
    "lump_sum_payment                 0\n",
    "property_value               15098\n",
    "occupancy_type                   0\n",
    "secured_by                       0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=config.TARGET)\n",
    "y = df[[config.TARGET]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=config.RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_parquet(config.INT_FILE_PATH / 'X_train.parquet')\n",
    "X_test.to_parquet(config.INT_FILE_PATH / 'X_test.parquet')\n",
    "y_train.to_parquet(config.INT_FILE_PATH / 'y_train.parquet')\n",
    "y_test.to_parquet(config.INT_FILE_PATH / 'y_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(config.INT_FILE_PATH / 'X_train.parquet')\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### property\n",
    "\n",
    "sns.histplot(X_train['property_value'])\n",
    "plt.show()\n",
    "\n",
    "X_train['property_value_binned'] = pd.qcut(X_train['property_value'], q=5, \n",
    "                                labels=['1', '2', '3', '4', '5'])\n",
    "X_train['property_value_binned'] = X_train['property_value_binned'].astype('object').fillna('missing')\n",
    "X_train['property_value_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['credit_score'])\n",
    "plt.show() \n",
    "\n",
    "\n",
    "X_train['credit_score_binned'] = pd.qcut(X_train['credit_score'], q=5, \n",
    "labels=['1', '2', '3', '4', '5'])\n",
    "\n",
    "X_train['credit_score_binned'] = X_train['credit_score'].astype('object').fillna('missing')\n",
    "X_train['credit_score_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['ltv'])\n",
    "plt.show()\n",
    "\n",
    "X_train['ltv_binned'] = pd.qcut(X_train['ltv'], q=5, \n",
    "labels=['1', '2', '3', '4', '5'])\n",
    "\n",
    "X_train['ltv_binned'] = X_train['ltv_binned'].astype('object').fillna('missing')\n",
    "\n",
    "X_train['ltv_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['dtir1'])\n",
    "plt.show()\n",
    "\n",
    "X_train['dtir1_binned'] = pd.qcut(X_train['dtir1'], q=5, \n",
    "labels=['1', '2', '3', '4', '5'])\n",
    "\n",
    "X_train['dtir1_binned'] = X_train['dtir1_binned'].astype('object').fillna('missing')\n",
    "\n",
    "X_train['dtir1_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['income'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [ 'dtir1', 'income', 'credit_score', 'property_value', 'ltv','rate_of_interest', 'upfront_charges', 'loan_limit', 'gender', 'approv_in_adv', 'loan_type', 'loan_purpose',\n",
    "       'credit_worthiness', 'open_credit', 'business_or_commercial',\n",
    "       'loan_amount', 'term', 'neg_ammortization', 'interest_only', 'lump_sum_payment',\n",
    "       'occupancy_type', 'total_units', \n",
    "       'credit_type', 'co_applicant_credit_type', 'age',\n",
    "       'submission_of_application', 'region',\n",
    "       'property_value_binned', 'credit_score_binned', 'ltv_binned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reindex(columns=seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train['credit_score_binned'] == 'missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "\n",
    "pp = Pipeline([\n",
    "        ('ohe', OneHotEncoder()),\n",
    "        ('rfc', rfc)\n",
    "     ])\n",
    "\n",
    "pp.fit(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "570095cd93adf9a4e6271b94630cfbadf31bbfe8ef42337a7894ca3063fc1c9a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
